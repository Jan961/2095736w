{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hdimvis.metrics.stress.stress import vectorised_stress,unvectorised_stress\n",
    "from hdimvis.data_fetchers.DataFetcher import DataFetcher\n",
    "from hdimvis.metrics.distance_measures.euclidian_and_manhattan import euclidean,manhattan\n",
    "import numpy as np\n",
    "import tracemalloc\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Fetching the \"mnist\" dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\.virtualenvs\\2095736w-0SnFieZ0\\lib\\site-packages\\sklearn\\datasets\\_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Dataset loaded\n",
      "Dataset shape: (70000, 784)\n"
     ]
    }
   ],
   "source": [
    "large_dataset = DataFetcher.fetch_data('mnist', size='max')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  10   60  110  160  210  260  310  360  410  460  510  560  610  660\n",
      "  710  760  810  860  910  960 1010 1060 1110 1160 1210 1260 1310 1360\n",
      " 1410 1460 1510 1560 1610 1660 1710 1760 1810 1860 1910 1960]\n"
     ]
    }
   ],
   "source": [
    "sizes = np.arange(10,2000, 50)\n",
    "print(sizes)\n",
    "\n",
    "\n",
    "vectorised_data = np.zeros((len(sizes),2)) # two for memory use (index 0) and time (index 1)\n",
    "un_vectorised_data = np.zeros((len(sizes),2))\n",
    "\n",
    "collected_data = [vectorised_data, un_vectorised_data]\n",
    "functions = [vectorised_stress, unvectorised_stress]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(248, 1322056)\n",
      "(2592, 268720)\n",
      "(248, 31446856)\n",
      "(5952, 1279256)\n",
      "(248, 125600632)\n",
      "(6838, 2543369)\n"
     ]
    }
   ],
   "source": [
    "for i, size in enumerate(sizes):\n",
    "    for j in range(2):\n",
    "        sample_indices = np.random.randint(0, 69999, size)\n",
    "        sample = large_dataset.data[sample_indices]\n",
    "        ld_positions = 20*np.random.rand(sample.shape[0],2)\n",
    "        stress_fn = functions[j]\n",
    "\n",
    "        tracemalloc.start()\n",
    "        stress1 = stress_fn(sample, ld_positions, euclidean)\n",
    "        collected_data[j][i,0] = tracemalloc.get_traced_memory()[1]\n",
    "        print(tracemalloc.get_traced_memory())\n",
    "        tracemalloc.stop()\n",
    "\n",
    "\n",
    "\n",
    "        start = perf_counter()\n",
    "        stress2 = stress_fn(sample, ld_positions, euclidean)\n",
    "        collected_data[j][i,1] = perf_counter() - start\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.32205600e+06 4.06300000e-04]\n",
      " [3.14468560e+07 8.99520000e-03]\n",
      " [1.25600632e+08 3.71306000e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(vectorised_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
