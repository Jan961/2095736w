{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "\n",
    "from hdimvis.data_fetchers.DataFetcher import DataFetcher\n",
    "from sklearn.decomposition import PCA\n",
    "from hdimvis.metrics.stress.stress import vectorised_stress\n",
    "from hdimvis.metrics.distance_measures.euclidian_and_manhattan import euclidean\n",
    "from hdimvis.algorithms.stochastic_ntet_algo.new_distance_calculations import compute_quartet_dhd,compute_quartet_dld\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Fetching the \"rna N3k\" dataset\n",
      "####################\n",
      "Dataset loaded\n",
      "Dataset shape: (3000, 50)\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "dataset = DataFetcher.fetch_data('rna N3k')\n",
    "data = dataset.data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "Xld = PCA(n_components=2, whiten=False, copy=True).fit_transform(data).astype(np.float64)\n",
    "Xld *= 10/np.std(Xld)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "def average_batch_stress(data: np.ndarray, batch_size: int):\n",
    "    N = data.shape[0]\n",
    "    perms = np.arange(N)\n",
    "    batch_indices =  np.arange(N - N % batch_size).reshape(-1, batch_size)\n",
    "    total_stress = 0\n",
    "\n",
    "    for batch in batch_indices:\n",
    "\n",
    "        quartet = perms[batch]\n",
    "        ld_points = Xld[quartet]\n",
    "        _, Dld_quartet = compute_quartet_dld(ld_points)\n",
    "        # Dld_quartet /= np.sum(Dld_quartet)\n",
    "        Dhd_quartet = compute_quartet_dhd(False,data[quartet], euclidean)\n",
    "        # Dhd_quartet /= np.sum(Dhd_quartet)\n",
    "\n",
    "        stress = np.sum(( Dhd_quartet - Dld_quartet)**2)\n",
    "        # stress = vectorised_stress(data[batch], np.random.randn(batch_size,2), euclidean)\n",
    "        total_stress += stress\n",
    "\n",
    "    return total_stress/batch_indices.shape[0]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1496092.9173862748\n"
     ]
    }
   ],
   "source": [
    "print(average_batch_stress(data, 20))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
